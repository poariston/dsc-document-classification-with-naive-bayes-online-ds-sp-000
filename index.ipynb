{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification with Naive Bayes\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lesson, you'll investigate another implementation of the Bayesian framework in order to classify YouTube videos into the appropriate topic. The dataset you'll be investigating again comes from Kaggle. For further information, you can check out the original dataset here: https://www.kaggle.com/extralime/math-lectures .\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:  \n",
    "\n",
    "- Implement document classification using Naive Bayes \n",
    "- Explain how to code a bag of words representation\n",
    "- Explain why it is necessary to use Laplacian smoothing correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes theorem for document classification\n",
    "\n",
    "A common example of using Bayes' theorem to classify documents is a spam filtering algorithm. You'll be exploring this application in the upcoming lab. To do this, you examine the question \"given this word (in the document) what is the probability that it is spam versus not spam?\" For example, perhaps you get a lot of \"special offer\" spam. In that case, the words \"special\" and \"offer\" may increase the probability that a given message is spam.\n",
    "\n",
    "Recall Bayes theorem:\n",
    "\n",
    " $$ \\large  P(A|B) = \\dfrac{P(B|A)P(A)}{P(B)}$$\n",
    "\n",
    "Applied to a document, one common implementation of Bayes' theorem is to use a bag of words representation. A bag of words representation takes a text document and converts it into a word frequency representation. For example, in a bag of words representation, the message:\n",
    "\n",
    "> \"Thomas Bayes was born in the early 1700s, although his exact date of birth is unknown. As a Presbyterian in England, he took an unconventional approach to education for his day since Oxford and Cambridge were tied to the Church of England.\"\n",
    "\n",
    "Would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Thomas': 1,\n",
       " 'Bayes': 1,\n",
       " 'was': 1,\n",
       " 'born': 1,\n",
       " 'in': 2,\n",
       " 'the': 2,\n",
       " 'early': 1,\n",
       " '1700s,': 1,\n",
       " 'although': 1,\n",
       " 'his': 2,\n",
       " 'exact': 1,\n",
       " 'date': 1,\n",
       " 'of': 2,\n",
       " 'birth': 1,\n",
       " 'is': 1,\n",
       " 'unknown.': 1,\n",
       " 'As': 1,\n",
       " 'a': 1,\n",
       " 'Presbyterian': 1,\n",
       " 'England,': 1,\n",
       " 'he': 1,\n",
       " 'took': 1,\n",
       " 'an': 1,\n",
       " 'unconventional': 1,\n",
       " 'approach': 1,\n",
       " 'to': 2,\n",
       " 'education': 1,\n",
       " 'for': 1,\n",
       " 'day': 1,\n",
       " 'since': 1,\n",
       " 'Oxford': 1,\n",
       " 'and': 1,\n",
       " 'Cambridge': 1,\n",
       " 'were': 1,\n",
       " 'tied': 1,\n",
       " 'Church': 1,\n",
       " 'England.': 1}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = \"Thomas Bayes was born in the early 1700s, although his exact date of birth is unknown. As a Presbyterian in England, he took an unconventional approach to education for his day since Oxford and Cambridge were tied to the Church of England.\"\n",
    "bag = {}\n",
    "for word in doc.split():\n",
    "    # Get the previous entry, or 0 if not yet documented; add 1\n",
    "    bag[word] = bag.get(word, 0) + 1 \n",
    "bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag.get('England.',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "bag.keys()\n",
    "bag.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional preprocessing techniques can also be applied to the document before applying a bag of words representation, many of which you'll explore later when further investigating Natural Language Processing (NLP) techniques. \n",
    "\n",
    "\n",
    "Once you've converted the document into a bag of words representation, you can then implement Bayes' theorem.\n",
    "Returning to the case of 'Spam' and 'Not Spam', you would have:\n",
    "\n",
    " $$ P(\\text{Spam | Word}) = \\dfrac{P(\\text{Word | Spam})P(\\text{Spam})}{P(\\text{Word})}$$  \n",
    "\n",
    "Using the bag of words representation, you can then define $P(\\text{Word | Spam})$ as\n",
    "\n",
    " $$P(\\text{Word | Spam}) = \\dfrac{\\text{Word Frequency in Document}}{\\text{Word Frequency Across All Spam Documents}}$$  \n",
    "\n",
    "However, this formulation has a problem: what if you encounter a word in the test set that was not present in the training set? This new word would have a frequency of zero! This would commit two grave sins. First, there would be a division by zero error. Secondly, the numerator would also be zero; if you were to simply modify the denominator, having a term with zero probability would cause the probability for the entire document to also be zero when you subsequently multiplied the conditional probabilities in Multinomial Bayes. To effectively counteract these issues, Laplacian smoothing is often used giving:   \n",
    "\n",
    " $$P(\\text{Word | Spam}) = \\dfrac{\\text{Word Frequency in Document} + 1}{\\text{Word Frequency Across All Spam Documents + Number of Words in Corpus Vocabulary}}$$  \n",
    "\n",
    "Now, to implement this in Python!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The following content is\\r\\nprovided under a C...</td>\n",
       "      <td>Calculus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In this sequence of segments,\\r\\nwe review som...</td>\n",
       "      <td>Probability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The following content is\\r\\nprovided under a C...</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The following\\r\\ncontent is provided under a C...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The following\\r\\ncontent is provided under a C...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text        label\n",
       "0  The following content is\\r\\nprovided under a C...     Calculus\n",
       "1  In this sequence of segments,\\r\\nwe review som...  Probability\n",
       "2  The following content is\\r\\nprovided under a C...           CS\n",
       "3  The following\\r\\ncontent is provided under a C...   Algorithms\n",
       "4  The following\\r\\ncontent is provided under a C...   Algorithms"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('raw_text.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this sequence of segments,\r\n",
      "we review some mathematical background that will be\r\n",
      "useful at various places in this course. Most of what is covered, with\r\n",
      "the exception of the last segment, is material that you\r\n",
      "may have seen before. But this could still be an\r\n",
      "opportunity to refresh some of these concepts. I should say that\r\n",
      "this is intended to be just a refresher. Our coverage is not going to\r\n",
      "be complete in any sense. What we will talk about is\r\n",
      "sets, various definitions related to sets, and some basic\r\n",
      "properties, including De Morgan's laws. We will talk about what a\r\n",
      "sequence is and what it means for a sequence to converge\r\n",
      "to something. We will talk about\r\n",
      "infinite series. And as an example, we will look\r\n",
      "at the geometric series. Then we will talk about some\r\n",
      "subtleties that arise when you have sums of terms that are\r\n",
      "indexed with multiple indices. And finally, probably the most\r\n",
      "sophisticated part, will be a discussion of countable versus\r\n",
      "uncountable sets. Countable sets are like\r\n",
      "the integers. Uncountable sets are\r\n",
      "like the real line. And they're fundamentally\r\n",
      "different. And this fundamental difference\r\n",
      "reflects itself into fundamentally different\r\n",
      "probabilistic models-- models that involve discrete\r\n",
      "experiments and outcomes versus models that involve\r\n",
      "continuous outcomes.\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear Algebra     152\n",
       "Probability        124\n",
       "CS                 104\n",
       "Diff. Eq.           93\n",
       "Algorithms          81\n",
       "Statistics          79\n",
       "Calculus            70\n",
       "Data Structures     62\n",
       "AI                  48\n",
       "Math for Eng.       28\n",
       "NLP                 19\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple two-class case\n",
    "\n",
    "To simplify the problem, you can start by subsetting to two specific classes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Algorithms    81\n",
       "Statistics    79\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df[df['label'].isin(['Algorithms', 'Statistics'])]\n",
    "df2['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The following\\r\\ncontent is provided under a C...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The following\\r\\ncontent is provided under a C...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The following content is\\r\\nprovided under a C...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The following content is\\r\\nprovided under a C...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The following content is\\r\\nprovided under a C...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text       label\n",
       "3   The following\\r\\ncontent is provided under a C...  Algorithms\n",
       "4   The following\\r\\ncontent is provided under a C...  Algorithms\n",
       "6   The following content is\\r\\nprovided under a C...  Algorithms\n",
       "16  The following content is\\r\\nprovided under a C...  Algorithms\n",
       "18  The following content is\\r\\nprovided under a C...  Algorithms"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((860, 2), (160, 2))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape,df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1      False\n",
       "2      False\n",
       "3       True\n",
       "4       True\n",
       "       ...  \n",
       "855    False\n",
       "856    False\n",
       "857    False\n",
       "858    False\n",
       "859    False\n",
       "Name: label, Length: 860, dtype: bool"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].isin(['Algorithms', 'Statistics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Algorithms    0.50625\n",
       "Statistics    0.49375\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['label'].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Algorithms': 0.50625, 'Statistics': 0.49375}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_classes = dict(df2['label'].value_counts(normalize=True))\n",
    "p_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     The following\\r\\ncontent is provided under a C...\n",
       "label                                           Algorithms\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df2['text']\n",
    "y = df2['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=17)\n",
    "train_df = pd.concat([X_train, y_train], axis=1) \n",
    "test_df = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>In our previous lesson, we saw what binary\\r\\n...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>The following content is\\r\\nprovided under a C...</td>\n",
       "      <td>Statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>OK, here we go with, quiz\\r\\nreview for the th...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>A lot of what we do with Laplace\\r\\ntransforms...</td>\n",
       "      <td>Statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Let us now discuss an\\r\\ninteresting fact abou...</td>\n",
       "      <td>Statistics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text       label\n",
       "196  In our previous lesson, we saw what binary\\r\\n...  Algorithms\n",
       "729  The following content is\\r\\nprovided under a C...  Statistics\n",
       "261  OK, here we go with, quiz\\r\\nreview for the th...  Algorithms\n",
       "185  A lot of what we do with Laplace\\r\\ntransforms...  Statistics\n",
       "294  Let us now discuss an\\r\\ninteresting fact abou...  Statistics"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>OPERATOR: -- The following content is\\r\\nprovi...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>[SOUND] Stanford University. &amp;gt;&amp;gt; We'll ge...</td>\n",
       "      <td>Statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Okay, this is linear\\r\\nalgebra, lecture four....</td>\n",
       "      <td>Statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>The following content is\\r\\nprovided under a C...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>The following content is\\r\\nprovided under a C...</td>\n",
       "      <td>Statistics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text       label\n",
       "685  OPERATOR: -- The following content is\\r\\nprovi...  Algorithms\n",
       "375  [SOUND] Stanford University. &gt;&gt; We'll ge...  Statistics\n",
       "338  Okay, this is linear\\r\\nalgebra, lecture four....  Statistics\n",
       "80   The following content is\\r\\nprovided under a C...  Algorithms\n",
       "828  The following content is\\r\\nprovided under a C...  Statistics"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the word frequency dictionary for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will be a nested dictionary of class_i : {word1:freq, word2:freq..., wordn:freq},.... class_m : {}\n",
    "class_word_freq = {} \n",
    "classes = train_df['label'].unique()\n",
    "for class_ in classes:\n",
    "    temp_df = train_df[train_df.label == class_]\n",
    "    bag = {}\n",
    "    for row in temp_df.index:\n",
    "        doc = temp_df['text'][row]\n",
    "        for word in doc.split():\n",
    "            bag[word] = bag.get(word, 0) + 1\n",
    "    class_word_freq[class_] = bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([729, 185, 294, 400, 677, 365, 599, 538, 481, 547, 822, 537, 281,\n",
      "            654, 533, 221, 277, 201, 690, 616, 136,  73, 309, 495, 239, 323,\n",
      "            476, 298, 432, 142,  58, 115, 839, 780, 465, 456,  77, 112, 364,\n",
      "            440, 561, 838, 750, 460, 549, 437, 273,  46, 841, 431, 286, 234,\n",
      "            808,  23, 316, 198, 129, 291, 778],\n",
      "           dtype='int64')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'following',\n",
       " 'content',\n",
       " 'is',\n",
       " 'provided',\n",
       " 'under',\n",
       " 'a',\n",
       " 'Creative',\n",
       " 'Commons',\n",
       " 'license.',\n",
       " 'Your',\n",
       " 'support',\n",
       " 'will',\n",
       " 'help',\n",
       " 'MIT',\n",
       " 'OpenCourseWare',\n",
       " 'continue',\n",
       " 'to',\n",
       " 'offer',\n",
       " 'high',\n",
       " 'quality',\n",
       " 'educational',\n",
       " 'resources',\n",
       " 'for',\n",
       " 'free.',\n",
       " 'To',\n",
       " 'make',\n",
       " 'a',\n",
       " 'donation',\n",
       " 'or',\n",
       " 'view',\n",
       " 'additional',\n",
       " 'materials',\n",
       " 'from',\n",
       " 'hundreds',\n",
       " 'of',\n",
       " 'MIT',\n",
       " 'courses,',\n",
       " 'visit',\n",
       " 'MIT',\n",
       " 'OpenCourseWare',\n",
       " 'at',\n",
       " 'ocw.mit.edu.',\n",
       " 'PROFESSOR:',\n",
       " 'OK.',\n",
       " 'So',\n",
       " \"let's\",\n",
       " 'get',\n",
       " 'started.',\n",
       " 'We',\n",
       " 'want',\n",
       " 'to',\n",
       " 'first',\n",
       " 'review',\n",
       " \"Wald's\",\n",
       " 'equality',\n",
       " 'a',\n",
       " 'little',\n",
       " 'bit.',\n",
       " \"Wald's\",\n",
       " 'equality',\n",
       " 'is',\n",
       " 'very',\n",
       " 'tricky',\n",
       " 'thing.',\n",
       " 'If',\n",
       " 'you',\n",
       " 'think',\n",
       " 'you',\n",
       " 'understand',\n",
       " 'it,',\n",
       " 'you',\n",
       " 'will',\n",
       " 'go',\n",
       " 'along.',\n",
       " 'And',\n",
       " 'at',\n",
       " 'some',\n",
       " 'point,',\n",
       " 'you',\n",
       " 'will',\n",
       " 'be',\n",
       " 'using',\n",
       " 'it',\n",
       " 'and',\n",
       " 'you',\n",
       " 'will',\n",
       " 'say,',\n",
       " 'I',\n",
       " \"don't\",\n",
       " 'understand',\n",
       " 'what',\n",
       " 'this',\n",
       " 'says.',\n",
       " 'And',\n",
       " 'that',\n",
       " 'will',\n",
       " 'happen',\n",
       " 'for',\n",
       " 'a',\n",
       " 'long',\n",
       " 'time.',\n",
       " 'It',\n",
       " 'still',\n",
       " 'happens',\n",
       " 'to',\n",
       " 'me',\n",
       " 'occasionally.',\n",
       " 'What',\n",
       " 'happens',\n",
       " 'is',\n",
       " 'you',\n",
       " 'work',\n",
       " 'with',\n",
       " 'it',\n",
       " 'for',\n",
       " 'longer',\n",
       " 'and',\n",
       " 'longer',\n",
       " 'times.',\n",
       " 'The',\n",
       " 'periods',\n",
       " 'when',\n",
       " 'it',\n",
       " 'becomes',\n",
       " 'confusing',\n",
       " 'become',\n",
       " 'rarer.',\n",
       " 'And',\n",
       " 'the',\n",
       " 'expected',\n",
       " 'time',\n",
       " 'to',\n",
       " 'straighten',\n",
       " 'it',\n",
       " 'out',\n",
       " 'becomes',\n",
       " 'smaller.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'a',\n",
       " 'strange',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'result.',\n",
       " 'So',\n",
       " 'we',\n",
       " 'started',\n",
       " 'out',\n",
       " 'with',\n",
       " 'a',\n",
       " 'stopping',\n",
       " 'trial',\n",
       " 'definition.',\n",
       " 'J',\n",
       " 'is',\n",
       " 'a',\n",
       " 'stopping',\n",
       " 'trial',\n",
       " 'for',\n",
       " 'a',\n",
       " 'sequence',\n",
       " 'of',\n",
       " 'random',\n",
       " 'variables.',\n",
       " 'If',\n",
       " \"it's\",\n",
       " 'a',\n",
       " 'random',\n",
       " 'variable',\n",
       " 'and',\n",
       " 'it',\n",
       " 'has',\n",
       " 'the',\n",
       " 'property',\n",
       " 'that',\n",
       " 'for',\n",
       " 'each',\n",
       " 'n',\n",
       " 'greater',\n",
       " 'than',\n",
       " 'or',\n",
       " 'equal',\n",
       " 'to',\n",
       " '1,',\n",
       " 'the',\n",
       " 'indicator',\n",
       " 'random',\n",
       " 'variable',\n",
       " 'indicator',\n",
       " 'of',\n",
       " 'J',\n",
       " 'equals',\n",
       " 'n',\n",
       " 'is',\n",
       " 'a',\n",
       " 'function',\n",
       " 'of',\n",
       " 'X1',\n",
       " 'to',\n",
       " 'X',\n",
       " 'sub',\n",
       " 'n.',\n",
       " 'In',\n",
       " 'other',\n",
       " 'words,',\n",
       " 'the',\n",
       " 'decision',\n",
       " 'of',\n",
       " 'whether',\n",
       " 'to',\n",
       " 'stop',\n",
       " 'at',\n",
       " 'time',\n",
       " 'n',\n",
       " 'is',\n",
       " 'a',\n",
       " 'function',\n",
       " 'of',\n",
       " '1',\n",
       " 'up',\n",
       " 'to',\n",
       " 'n.',\n",
       " 'A',\n",
       " 'possibly',\n",
       " 'effective',\n",
       " 'stopping',\n",
       " 'trial',\n",
       " 'is',\n",
       " 'the',\n",
       " 'same,',\n",
       " 'except',\n",
       " 'that',\n",
       " 'might',\n",
       " 'be',\n",
       " 'a',\n",
       " 'defective',\n",
       " 'random',\n",
       " 'variable.',\n",
       " 'And',\n",
       " 'the',\n",
       " 'reason',\n",
       " 'you',\n",
       " 'want',\n",
       " 'to',\n",
       " 'have',\n",
       " 'possibly',\n",
       " 'defective',\n",
       " 'random',\n",
       " 'variables',\n",
       " 'is',\n",
       " 'that',\n",
       " 'before',\n",
       " 'you',\n",
       " 'start',\n",
       " 'analyzing',\n",
       " 'something',\n",
       " 'that',\n",
       " 'might',\n",
       " 'be',\n",
       " 'a',\n",
       " 'stopping',\n",
       " 'rule,',\n",
       " 'you',\n",
       " 'generally',\n",
       " 'have',\n",
       " 'no',\n",
       " 'way',\n",
       " 'of',\n",
       " 'knowing',\n",
       " 'whether',\n",
       " 'that',\n",
       " 'actually',\n",
       " 'is',\n",
       " 'a',\n",
       " 'stopping',\n",
       " 'rule',\n",
       " 'or',\n",
       " 'whether',\n",
       " \"it's\",\n",
       " 'a',\n",
       " 'detective',\n",
       " 'stopping',\n",
       " 'rule.',\n",
       " 'So',\n",
       " 'you',\n",
       " 'might',\n",
       " 'as',\n",
       " 'well',\n",
       " 'just',\n",
       " 'say',\n",
       " \"it's\",\n",
       " 'a',\n",
       " 'defective',\n",
       " 'stopping',\n",
       " 'rule',\n",
       " 'to',\n",
       " 'start',\n",
       " 'with',\n",
       " 'and',\n",
       " 'show',\n",
       " 'that',\n",
       " \"it's\",\n",
       " 'not.',\n",
       " 'Then',\n",
       " 'from',\n",
       " 'that,',\n",
       " 'we',\n",
       " 'went',\n",
       " 'on',\n",
       " 'to',\n",
       " \"Wald's\",\n",
       " 'equality',\n",
       " 'which',\n",
       " 'added',\n",
       " 'the',\n",
       " 'condition',\n",
       " 'that',\n",
       " 'X',\n",
       " 'sub',\n",
       " 'n',\n",
       " 'that',\n",
       " 'this',\n",
       " 'is',\n",
       " 'based',\n",
       " 'on',\n",
       " 'is',\n",
       " 'a',\n",
       " 'sequence',\n",
       " 'of',\n",
       " 'IID',\n",
       " 'random',\n",
       " 'variables.',\n",
       " 'To',\n",
       " 'be',\n",
       " 'a',\n",
       " 'stopping',\n",
       " 'trial,',\n",
       " 'you',\n",
       " \"don't\",\n",
       " 'need',\n",
       " 'IID',\n",
       " 'random',\n",
       " 'variables.',\n",
       " 'You',\n",
       " \"don't\",\n",
       " 'need',\n",
       " 'any',\n",
       " 'restriction',\n",
       " 'at',\n",
       " 'all,',\n",
       " 'other',\n",
       " 'than',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'you',\n",
       " 'can',\n",
       " 'make',\n",
       " 'a',\n",
       " 'decision',\n",
       " 'on',\n",
       " 'when',\n",
       " 'to',\n",
       " 'stop',\n",
       " 'based',\n",
       " 'on',\n",
       " 'what',\n",
       " \"you've\",\n",
       " 'already',\n",
       " 'seen.',\n",
       " \"That's\",\n",
       " 'the',\n",
       " 'only',\n",
       " 'condition',\n",
       " 'there.',\n",
       " \"Wald's\",\n",
       " 'equality',\n",
       " 'is',\n",
       " 'based',\n",
       " 'on',\n",
       " 'this',\n",
       " 'extra',\n",
       " 'condition',\n",
       " 'that',\n",
       " 'the',\n",
       " 'random',\n",
       " 'variables',\n",
       " 'are',\n",
       " 'IID.',\n",
       " 'Each',\n",
       " 'of',\n",
       " 'them,',\n",
       " 'with',\n",
       " 'some',\n",
       " 'mean,',\n",
       " 'X',\n",
       " 'bar.',\n",
       " 'If',\n",
       " 'J',\n",
       " 'is',\n",
       " 'a',\n",
       " 'stopping',\n",
       " 'trial',\n",
       " 'and',\n",
       " 'as',\n",
       " 'the',\n",
       " 'expected',\n",
       " 'value',\n",
       " 'of',\n",
       " 'J',\n",
       " 'is',\n",
       " 'less',\n",
       " 'than',\n",
       " 'infinity,',\n",
       " 'then',\n",
       " 'the',\n",
       " 'sum',\n",
       " 'S',\n",
       " 'sub',\n",
       " 'J',\n",
       " 'at',\n",
       " 'the',\n",
       " 'stopping',\n",
       " 'trial,',\n",
       " 'J,',\n",
       " 'satisfies',\n",
       " 'this',\n",
       " 'relationship',\n",
       " 'here.',\n",
       " 'And',\n",
       " 'remember',\n",
       " 'we',\n",
       " 'proved',\n",
       " 'that',\n",
       " 'last',\n",
       " 'time.',\n",
       " 'And',\n",
       " 'the',\n",
       " 'key',\n",
       " 'to',\n",
       " 'proving',\n",
       " 'it,',\n",
       " 'the',\n",
       " 'hard',\n",
       " 'part',\n",
       " 'of',\n",
       " 'it--',\n",
       " 'well,',\n",
       " \"it's\",\n",
       " 'not',\n",
       " 'hard',\n",
       " 'if',\n",
       " 'you',\n",
       " 'see',\n",
       " 'it.',\n",
       " 'But',\n",
       " \"what's\",\n",
       " 'difficult',\n",
       " 'is',\n",
       " 'when',\n",
       " 'you',\n",
       " 'start',\n",
       " 'looking',\n",
       " 'at',\n",
       " 'how',\n",
       " 'you',\n",
       " 'find',\n",
       " 'the',\n",
       " 'expected',\n",
       " 'value',\n",
       " 'of',\n",
       " 'S',\n",
       " 'sub',\n",
       " 'J',\n",
       " \"that's\",\n",
       " 'equal',\n",
       " 'to',\n",
       " 'a',\n",
       " 'sum',\n",
       " 'over',\n",
       " 'n',\n",
       " 'of',\n",
       " 'X',\n",
       " 'sub',\n",
       " 'n',\n",
       " 'times',\n",
       " 'the',\n",
       " 'indicator',\n",
       " 'function',\n",
       " 'of',\n",
       " 'J',\n",
       " 'being',\n",
       " 'greater',\n",
       " 'than',\n",
       " 'or',\n",
       " 'equal',\n",
       " 'to',\n",
       " 'n.',\n",
       " 'Now',\n",
       " 'the',\n",
       " 'condition',\n",
       " 'here',\n",
       " 'is',\n",
       " 'that',\n",
       " 'this',\n",
       " 'indicator',\n",
       " 'at',\n",
       " 'J',\n",
       " 'equals',\n",
       " 'n',\n",
       " 'is',\n",
       " 'a',\n",
       " 'function',\n",
       " 'of',\n",
       " 'these',\n",
       " 'quantities',\n",
       " 'here.',\n",
       " 'When',\n",
       " 'you',\n",
       " 'add',\n",
       " 'the',\n",
       " 'IID',\n",
       " 'quantity',\n",
       " 'down',\n",
       " 'here,',\n",
       " 'what',\n",
       " 'you',\n",
       " 'find',\n",
       " 'then',\n",
       " 'is',\n",
       " 'the',\n",
       " 'indicator',\n",
       " 'function',\n",
       " 'for',\n",
       " 'J',\n",
       " 'greater',\n",
       " 'than',\n",
       " 'or',\n",
       " 'equal',\n",
       " 'to',\n",
       " 'n.',\n",
       " \"It's\",\n",
       " 'also',\n",
       " 'the',\n",
       " 'indicator',\n",
       " 'function',\n",
       " 'for',\n",
       " 'J',\n",
       " '1',\n",
       " 'minus',\n",
       " 'the',\n",
       " 'indicator',\n",
       " 'function',\n",
       " 'for',\n",
       " 'J',\n",
       " 'less',\n",
       " 'than',\n",
       " 'n.',\n",
       " \"It's\",\n",
       " 'independent',\n",
       " 'of',\n",
       " 'X1',\n",
       " 'up',\n",
       " 'to',\n",
       " 'X',\n",
       " 'sub',\n",
       " 'blah,',\n",
       " 'blah,',\n",
       " 'blah.',\n",
       " 'That',\n",
       " 'indicator',\n",
       " 'random',\n",
       " 'variable',\n",
       " 'is',\n",
       " 'then',\n",
       " 'a',\n",
       " 'function',\n",
       " 'only',\n",
       " 'of',\n",
       " 'X1',\n",
       " 'up',\n",
       " 'to',\n",
       " 'X',\n",
       " 'sub',\n",
       " 'n',\n",
       " 'minus',\n",
       " '1,',\n",
       " 'because',\n",
       " \"it's\",\n",
       " '1',\n",
       " 'minus',\n",
       " 'the',\n",
       " 'indicator',\n",
       " 'of',\n",
       " 'J',\n",
       " 'less',\n",
       " 'than',\n",
       " 'or',\n",
       " 'equal',\n",
       " 'to',\n",
       " 'n',\n",
       " 'minus',\n",
       " '1.',\n",
       " 'J',\n",
       " 'less',\n",
       " 'than',\n",
       " 'n,',\n",
       " 'which',\n",
       " 'means',\n",
       " 'that',\n",
       " 'X1',\n",
       " 'up',\n",
       " 'to',\n",
       " 'X',\n",
       " 'n',\n",
       " 'minus',\n",
       " '1',\n",
       " 'is',\n",
       " 'independent',\n",
       " 'of',\n",
       " 'Xn.',\n",
       " 'And',\n",
       " 'X1',\n",
       " 'up',\n",
       " 'to',\n",
       " 'X',\n",
       " 'n',\n",
       " 'minus',\n",
       " '1',\n",
       " 'is',\n",
       " 'what',\n",
       " 'determines',\n",
       " 'this',\n",
       " 'indicator',\n",
       " 'function',\n",
       " 'J',\n",
       " 'less',\n",
       " 'than',\n",
       " 'n.',\n",
       " \"It's\",\n",
       " 'the',\n",
       " 'J',\n",
       " 'less',\n",
       " 'than',\n",
       " 'n',\n",
       " 'which',\n",
       " 'is',\n",
       " 'important.',\n",
       " 'So',\n",
       " 'we',\n",
       " 'got',\n",
       " 'that',\n",
       " \"Wald's\",\n",
       " 'equality.',\n",
       " 'What',\n",
       " 'I',\n",
       " 'want',\n",
       " 'to',\n",
       " 'do',\n",
       " 'today',\n",
       " 'to',\n",
       " 'start',\n",
       " 'off',\n",
       " 'with',\n",
       " 'is',\n",
       " 'to',\n",
       " 'do',\n",
       " 'the',\n",
       " 'elementary',\n",
       " 'renewal',\n",
       " 'theorem,',\n",
       " 'which',\n",
       " 'is',\n",
       " 'a',\n",
       " 'strange',\n",
       " 'result.',\n",
       " \"Wald's\",\n",
       " 'equality,',\n",
       " 'you',\n",
       " 'can',\n",
       " 'use',\n",
       " 'it',\n",
       " 'to',\n",
       " 'determine',\n",
       " 'the',\n",
       " 'expected',\n",
       " 'value',\n",
       " 'of',\n",
       " 'N',\n",
       " 'of',\n",
       " 't.',\n",
       " 'Now',\n",
       " 'why',\n",
       " 'do',\n",
       " 'we',\n",
       " 'want',\n",
       " 'to',\n",
       " 'determine',\n",
       " 'the',\n",
       " 'expected',\n",
       " 'value',\n",
       " 'of',\n",
       " 'N',\n",
       " 'of',\n",
       " 't?',\n",
       " 'We',\n",
       " 'already',\n",
       " 'have',\n",
       " 'shown',\n",
       " 'in',\n",
       " 'great',\n",
       " 'generality',\n",
       " 'that',\n",
       " \"there's\",\n",
       " 'a',\n",
       " 'very',\n",
       " 'nice,',\n",
       " 'with',\n",
       " 'probability,',\n",
       " 'one',\n",
       " 'type',\n",
       " 'limit',\n",
       " 'theorem',\n",
       " 'associated',\n",
       " 'with',\n",
       " 'N',\n",
       " 'of',\n",
       " 't',\n",
       " 'over',\n",
       " 't.',\n",
       " 'We',\n",
       " 'know',\n",
       " 'that',\n",
       " 'N',\n",
       " 'of',\n",
       " 't',\n",
       " 'over',\n",
       " 't',\n",
       " 'approaches',\n",
       " 't',\n",
       " 'with',\n",
       " 'probability',\n",
       " '1.',\n",
       " 'Namely,',\n",
       " 'all',\n",
       " 'the',\n",
       " 'sample',\n",
       " 'functions,',\n",
       " 'except',\n",
       " 'a',\n",
       " 'set',\n",
       " 'of',\n",
       " 'probability',\n",
       " '0,',\n",
       " 'all',\n",
       " 'approach',\n",
       " 'this',\n",
       " 'same',\n",
       " 'constant,',\n",
       " '1',\n",
       " 'over',\n",
       " 'X',\n",
       " 'bar.',\n",
       " 'So',\n",
       " 'it',\n",
       " 'seems',\n",
       " 'that',\n",
       " 'we',\n",
       " 'know',\n",
       " 'everything',\n",
       " 'we',\n",
       " 'want',\n",
       " 'to',\n",
       " 'know',\n",
       " 'about',\n",
       " 'the',\n",
       " 'expected',\n",
       " 'value',\n",
       " 'of',\n",
       " 'N',\n",
       " 'of',\n",
       " 't,',\n",
       " 'about',\n",
       " 'N',\n",
       " 'of',\n",
       " 't,',\n",
       " 'and',\n",
       " 'everything',\n",
       " 'else.',\n",
       " 'But',\n",
       " 'no.',\n",
       " 'And',\n",
       " 'there',\n",
       " 'are',\n",
       " 'two',\n",
       " 'reasons',\n",
       " 'why',\n",
       " 'you',\n",
       " 'want',\n",
       " 'to',\n",
       " 'do',\n",
       " 'something',\n",
       " 'more',\n",
       " 'than',\n",
       " 'that.',\n",
       " 'One',\n",
       " 'of',\n",
       " 'them',\n",
       " 'is',\n",
       " 'that',\n",
       " 'very',\n",
       " 'often',\n",
       " 'you',\n",
       " 'want',\n",
       " 'to',\n",
       " 'know',\n",
       " 'how',\n",
       " 'N',\n",
       " 'of',\n",
       " 't',\n",
       " 'over',\n",
       " 't',\n",
       " 'approaches',\n",
       " 'the',\n",
       " 'limit',\n",
       " 'of',\n",
       " '1',\n",
       " 'over',\n",
       " 'X',\n",
       " 'bar.',\n",
       " 'The',\n",
       " 'other',\n",
       " 'is',\n",
       " 'that',\n",
       " 'sometimes',\n",
       " 'you',\n",
       " 'really',\n",
       " 'are',\n",
       " 'interested',\n",
       " 'in,',\n",
       " 'what',\n",
       " 'is',\n",
       " 'N',\n",
       " 'of',\n",
       " 't',\n",
       " 'at',\n",
       " 'some',\n",
       " 'finite',\n",
       " 'value',\n",
       " 'of',\n",
       " 't?',\n",
       " 'N',\n",
       " 'of',\n",
       " 't',\n",
       " 'is',\n",
       " 'a',\n",
       " 'random',\n",
       " 'variable,',\n",
       " 'some',\n",
       " 'finite',\n",
       " 'value',\n",
       " 'of',\n",
       " 't.',\n",
       " 'So',\n",
       " 'you',\n",
       " \"can't\",\n",
       " 'evaluate',\n",
       " 'it.',\n",
       " 'But',\n",
       " 'at',\n",
       " 'least',\n",
       " 'you',\n",
       " 'would',\n",
       " 'like',\n",
       " 'to',\n",
       " 'know',\n",
       " 'what',\n",
       " 'its',\n",
       " 'expected',\n",
       " 'value',\n",
       " 'is.',\n",
       " 'You',\n",
       " 'might',\n",
       " 'want',\n",
       " 'to',\n",
       " 'know',\n",
       " 'what',\n",
       " \"it's\",\n",
       " 'variance',\n",
       " 'is',\n",
       " 'too.',\n",
       " 'But',\n",
       " 'people',\n",
       " 'who',\n",
       " 'study',\n",
       " 'renewal',\n",
       " 'theory',\n",
       " 'have',\n",
       " 'spent',\n",
       " 'an',\n",
       " 'enormous',\n",
       " 'amount',\n",
       " 'of',\n",
       " 'time',\n",
       " 'on',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'find',\n",
       " 'the',\n",
       " 'expected',\n",
       " 'value',\n",
       " 'of',\n",
       " 'N',\n",
       " 'of',\n",
       " 't.',\n",
       " \"It's\",\n",
       " 'the',\n",
       " 'basic',\n",
       " 'problem',\n",
       " 'that',\n",
       " 'people',\n",
       " 'work',\n",
       " 'on',\n",
       " 'all',\n",
       " 'the',\n",
       " 'time.',\n",
       " 'The',\n",
       " 'elementary',\n",
       " 'renewal',\n",
       " 'theorem',\n",
       " 'is',\n",
       " 'something',\n",
       " 'which',\n",
       " 'says',\n",
       " 'a',\n",
       " 'little',\n",
       " 'more',\n",
       " 'for',\n",
       " 'finite',\n",
       " 'times.',\n",
       " 'And',\n",
       " 'it',\n",
       " 'actually',\n",
       " 'says',\n",
       " 'the',\n",
       " 'expected',\n",
       " 'value',\n",
       " 'of',\n",
       " 'N',\n",
       " 'of',\n",
       " 't',\n",
       " 'over',\n",
       " 't',\n",
       " 'and',\n",
       " 'the',\n",
       " 'limit',\n",
       " 'is',\n",
       " 'equal',\n",
       " 'to',\n",
       " '1',\n",
       " 'over',\n",
       " 'X',\n",
       " 'bar.',\n",
       " 'Sounds',\n",
       " 'like',\n",
       " 'much',\n",
       " 'less',\n",
       " 'than',\n",
       " 'what',\n",
       " \"we've\",\n",
       " 'done',\n",
       " 'before.',\n",
       " 'And',\n",
       " 'perhaps',\n",
       " 'this',\n",
       " 'is',\n",
       " 'because',\n",
       " 'this',\n",
       " 'was',\n",
       " 'a',\n",
       " 'computational',\n",
       " 'thing',\n",
       " 'that',\n",
       " 'people',\n",
       " 'could',\n",
       " 'do',\n",
       " 'without',\n",
       " 'computers,',\n",
       " 'before',\n",
       " 'computers',\n",
       " 'came',\n",
       " 'along.',\n",
       " 'And',\n",
       " 'all',\n",
       " 'the',\n",
       " 'work',\n",
       " 'on',\n",
       " 'renewal',\n",
       " 'theory',\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(temp_df.index)\n",
    "temp_df['text'][729].split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Algorithms' 'Statistics']\n"
     ]
    }
   ],
   "source": [
    "print(train_df['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>In our previous lesson, we saw what binary\\r\\n...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>OK, here we go with, quiz\\r\\nreview for the th...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>We have already seen\\r\\nan example in which we...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>So, we're gonna start on our very\\r\\nlast topi...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>A lot of what you'll learn in\\r\\ndifferential ...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>The following content is\\r\\nprovided under a C...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>[MUSIC] Stanford University. &amp;gt;&amp;gt; Alright!...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>The following content is\\r\\nprovided under a C...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>Let us now study a very\\r\\nimportant counting ...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>The following content is\\r\\nprovided under a C...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text       label\n",
       "196  In our previous lesson, we saw what binary\\r\\n...  Algorithms\n",
       "261  OK, here we go with, quiz\\r\\nreview for the th...  Algorithms\n",
       "434  We have already seen\\r\\nan example in which we...  Algorithms\n",
       "131  So, we're gonna start on our very\\r\\nlast topi...  Algorithms\n",
       "647  A lot of what you'll learn in\\r\\ndifferential ...  Algorithms\n",
       "..                                                 ...         ...\n",
       "355  The following content is\\r\\nprovided under a C...  Algorithms\n",
       "167  [MUSIC] Stanford University. &gt;&gt; Alright!...  Algorithms\n",
       "821  The following content is\\r\\nprovided under a C...  Algorithms\n",
       "716  Let us now study a very\\r\\nimportant counting ...  Algorithms\n",
       "566  The following content is\\r\\nprovided under a C...  Algorithms\n",
       "\n",
       "[61 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df [train_df.label=='Algorithms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Algorithms', 'Statistics'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_word_freq.keys()\n",
    "# class_word_freq['Algorithms'].keys()\n",
    "# class_word_freq['Algorithms'].values()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the total corpus words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>In our previous lesson, we saw what binary\\r\\n...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>The following content is\\r\\nprovided under a C...</td>\n",
       "      <td>Statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>OK, here we go with, quiz\\r\\nreview for the th...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>A lot of what we do with Laplace\\r\\ntransforms...</td>\n",
       "      <td>Statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Let us now discuss an\\r\\ninteresting fact abou...</td>\n",
       "      <td>Statistics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text       label\n",
       "196  In our previous lesson, we saw what binary\\r\\n...  Algorithms\n",
       "729  The following content is\\r\\nprovided under a C...  Statistics\n",
       "261  OK, here we go with, quiz\\r\\nreview for the th...  Algorithms\n",
       "185  A lot of what we do with Laplace\\r\\ntransforms...  Statistics\n",
       "294  Let us now discuss an\\r\\ninteresting fact abou...  Statistics"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23977"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = set()\n",
    "for text in train_df['text']:\n",
    "    for word in text.split():\n",
    "        vocabulary.add(word)\n",
    "V = len(vocabulary)\n",
    "V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a bag of words function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_it(doc):\n",
    "    bag = {}\n",
    "    for word in doc.split():\n",
    "        bag[word] = bag.get(word, 0) + 1\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def classify_doc(doc, class_word_freq, p_classes, V, return_posteriors=False):\n",
    "    bag = bag_it(doc)\n",
    "    classes = []\n",
    "    posteriors = []\n",
    "    for class_ in class_word_freq.keys():\n",
    "        p = p_classes[class_]\n",
    "        for word in bag.keys():\n",
    "            num = bag[word]+1  #(laplacian smoothing formula)\n",
    "            denom = class_word_freq[class_].get(word, 0) + V  #(laplacian smoothing formula)\n",
    "            p *= (num/denom)\n",
    "        classes.append(class_)\n",
    "        posteriors.append(p)\n",
    "    if return_posteriors:\n",
    "        print(posteriors)\n",
    "    return classes[np.argmax(posteriors)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Algorithms'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_doc(train_df.iloc[0]['text'], class_word_freq, p_classes, V, return_posteriors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00029183480194350654\n",
      "1.1869958592024182e-07\n",
      "1.974952554723045e-11\n",
      "2.470749651446678e-15\n",
      "8.041780511324361e-18\n",
      "6.698971645070066e-22\n",
      "2.3354022623811047e-25\n",
      "1.359598788811355e-28\n",
      "9.044395734650623e-32\n",
      "1.1312093389457129e-35\n",
      "9.420856455929317e-40\n",
      "4.201817338329582e-43\n",
      "1.3077274121061123e-45\n",
      "4.1689743179127235e-48\n",
      "5.2138248097958016e-52\n",
      "3.596154599238396e-55\n",
      "5.533609693000033e-59\n",
      "2.0175627453768643e-61\n",
      "1.6805320439605715e-65\n",
      "6.299108073651719e-69\n",
      "7.66470258404184e-72\n",
      "1.786432221136401e-74\n",
      "2.9896172877682048e-77\n",
      "6.223183363380943e-81\n",
      "2.2565025692127025e-84\n",
      "4.692249052220217e-88\n",
      "6.43778215175608e-91\n",
      "5.369292870522169e-95\n",
      "1.2481696224441702e-97\n",
      "6.97141097399576e-101\n",
      "3.272633659790787e-104\n",
      "1.0890627819603286e-107\n",
      "1.8097507905119497e-111\n",
      "5.510466146407909e-114\n",
      "6.891241168545468e-118\n",
      "1.6731389787060318e-120\n",
      "2.790425248008725e-124\n",
      "6.859544824374896e-127\n",
      "2.001284281691505e-130\n",
      "9.98146773910975e-134\n",
      "8.325174310112807e-138\n",
      "6.944010601478695e-142\n",
      "3.390216331736211e-145\n",
      "5.1264612230281274e-148\n",
      "6.377782063981248e-152\n",
      "5.315704337373936e-156\n",
      "4.431230691375405e-160\n",
      "3.679354582451451e-164\n",
      "4.602453299151212e-168\n",
      "5.463717263841413e-172\n",
      "2.2749374459097363e-175\n",
      "3.791246472643507e-179\n",
      "1.3455800242050463e-182\n",
      "1.1218308593147245e-186\n",
      "1.0262496945787326e-189\n",
      "1.1835377850466573e-192\n",
      "9.831272874915126e-197\n",
      "5.445180213190321e-200\n",
      "1.102977680519835e-203\n",
      "9.18994901282982e-208\n",
      "4.585993602277118e-211\n",
      "5.737033821288251e-215\n",
      "2.0863627117987013e-218\n",
      "2.865882845877337e-221\n",
      "9.537841237631541e-225\n",
      "2.783726178428152e-228\n",
      "7.55538104338609e-232\n",
      "2.5187751946947e-235\n",
      "3.983197904158615e-239\n",
      "3.320853644719342e-243\n",
      "2.769801613678087e-247\n",
      "4.6201861779450995e-251\n",
      "1.12870997832535e-254\n",
      "1.9861482213941084e-257\n",
      "5.502666646781746e-261\n",
      "1.8055589669929028e-264\n",
      "4.513521290708031e-268\n",
      "1.6666676903283257e-271\n",
      "1.186005867796397e-274\n",
      "1.3272883374990763e-277\n",
      "8.851539429803776e-281\n",
      "1.8451470503218076e-284\n",
      "6.020055629108671e-288\n",
      "5.449807581285111e-291\n",
      "4.5451045254869355e-295\n",
      "9.168849568426142e-298\n",
      "7.615323561815733e-302\n",
      "2.219563847804061e-305\n",
      "3.6952698706469e-309\n",
      "1.19024676753e-312\n",
      "1.96102935e-316\n",
      "1.6354e-320\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "doc=train_df.iloc[0]['text'] # one of the texts in train_df\n",
    "class_word_freq  # = the word frequency dictionary for each class (algo or stat)\n",
    "p_classes  # count of the occurences of each class in df_train\n",
    "V # total corpus words number\n",
    "\n",
    "bag = bag_it(doc)\n",
    "classes = []\n",
    "posteriors = []\n",
    "class_ = 'Algorithms'\n",
    "p = p_classes[class_]\n",
    "for word in bag.keys():\n",
    "    num = bag[word]+1\n",
    "    denom = class_word_freq[class_].get(word, 0) + V\n",
    "    p *= (num/denom)\n",
    "    print(p)\n",
    "#         classes.append(class_)\n",
    "#         posteriors.append(p)\n",
    "#     if return_posteriors:\n",
    "#         print(posteriors)\n",
    "#     return classes[np.argmax(posteriors)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoid underflow\n",
    "\n",
    "As you can see from the output above, repeatedly multiplying small probabilities can lead to underflow; rounding to zero due to numerical approximation limitations. As such, a common alternative is to add the logarithms of the probabilities as opposed to multiplying the raw probabilities themselves. If this is alien to you, it might be worth reviewing some algebra rules of exponents and logarithms briefly:  \n",
    "\n",
    "$ e^x \\cdot e^y = e^{x+y}$  \n",
    "$ log_{e}(e)=1 $  \n",
    "$ e^{log(x)} = x$  \n",
    "\n",
    "With that, here's an updated version of the function using log probabilities to avoid underflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_doc(doc, class_word_freq, p_classes, V, return_posteriors=False):\n",
    "    bag = bag_it(doc)\n",
    "    classes = []\n",
    "    posteriors = []\n",
    "    for class_ in class_word_freq.keys():\n",
    "        p = np.log(p_classes[class_])\n",
    "        for word in bag.keys():\n",
    "            num = bag[word]+1\n",
    "            denom = class_word_freq[class_].get(word, 0) + V\n",
    "            p += np.log(num/denom)\n",
    "        classes.append(class_)\n",
    "        posteriors.append(p)\n",
    "    if return_posteriors:\n",
    "        print(posteriors)\n",
    "    return classes[np.argmax(posteriors)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5578.267536771343, -5577.213285866603]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Statistics'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_doc(train_df.iloc[0]['text'], class_word_freq, p_classes, V, return_posteriors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2572.1544445158343, -2571.311308656896]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Statistics'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_doc(train_df.iloc[10]['text'], class_word_freq, p_classes, V, return_posteriors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4602.602622507951, -4601.755644621728]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Statistics'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_doc(train_df.iloc[12]['text'], class_word_freq, p_classes, V, return_posteriors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.508333\n",
       "True     0.491667\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_train = X_train.map(lambda x: classify_doc(x, class_word_freq, p_classes, V))\n",
    "residuals = y_train == y_hat_train\n",
    "residuals.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this algorithm leaves a lot to be desired. A measly 49% accuracy is nothing to write home about. (In fact, it's slightly worse than random guessing!) In practice, substantial additional preprocessing including removing stop words and using stemming or lemmatisation would be required. Even then, Naive Bayes might still not be the optimal algorithm. Nonetheless, it is a worthwhile exercise and a comprehendible algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lesson, you got to see another application of Bayes' theorem as a means to do some rough documentation classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
